{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Solving XOR With a 2x2x1 Neural Network with tflearn\n",
    " \n",
    "Simplest possible feed forward neural network capable solving the XOR problem. \n",
    "\n",
    "The example serves as a syntax guide for developers learning to use Tensorflow with tflearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tflearn import DNN\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a dataset consisting of four possible combinations of inputs (X) and their corresponding classes (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = [[0,0], [0,1], [1,0], [1,1]]\n",
    "Y = [[0], [1], [1], [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_layer = input_data(shape=[None, 2]) #input layer of size 2\n",
    "hidden_layer = fully_connected(input_layer , 2, activation='tanh') #hidden layer of size 2\n",
    "output_layer = fully_connected(hidden_layer, 1, activation='tanh') #output layer of size 1\n",
    "\n",
    "regression = regression(output_layer , optimizer='sgd', loss='binary_crossentropy', learning_rate=5)\n",
    "model = DNN(regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, Y, n_epoch=5000, show_metric=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an accuracy of 99.9%\n",
    "\n",
    "Now let's check whether our model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, True, False]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i[0] > 0 for i in model.predict(X)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight analisys\n",
    "\n",
    "Unlike AND and OR, XOR problem's outputs are not linearly separable. Therefore, we had to introduce another hidden layer. That way, each node in the hidden layer represents one of the linearly separable logical operation (AND, OR, NOR, ...) and the output layer will act as another logical operation fed by outputs from the previous layer.\n",
    "\n",
    "A simple example of such an expression is:\n",
    "$XOR(X_1, X_2) = AND(OR(X_1, X_2), NAND(X_1, X_2))$\n",
    "\n",
    "Now let's see what our network came up with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights in layer1:  [[ 3.86708593 -3.11288071]\n",
      " [ 3.87053323 -3.1126008 ]] , Biases in layer1:  [-1.82562542  4.58438063]\n",
      "Weights in layer2:  [[ 5.19325304]\n",
      " [ 5.23881006]] , Biases in layer2:  [-4.87336922]\n"
     ]
    }
   ],
   "source": [
    "print('Weights in layer1: ', model.get_weights(hidden_layer.W), ', Biases in layer1: ', model.get_weights(hidden_layer.b))\n",
    "print('Weights in layer2: ', model.get_weights(output_layer.W), ', Biases in layer2: ', model.get_weights(output_layer.b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the activations for different inputs, we can estimate what logical operation each node represents\n",
    "\n",
    "| Input | Node1 (Hidden Layer) | Node2 (Hidden Layer)   | Output Node |\n",
    "|------|------|------|------|\n",
    "|   [0,0]  |-1|1|-1|\n",
    "|   [0,1]  |1|1|1|\n",
    "|   [1,0]  |1|1|1|\n",
    "|   [1,1]  |1|-1|-1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Node1$ output is true always apart from when both inputs are false. $Node1$ represents $OR$\n",
    "\n",
    "$Node2$ output is false only when both inputs are false. It represents $NAND$\n",
    "\n",
    "$Output Node$ is true only when both $Node1$ and $Node2$ are true. It represents $AND$ operation of activations of the previous layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Walla! Our network therefore learned to solve XOR on its own using this equation: \n",
    "\n",
    "$$XOR(X_1, X_2) = AND(Node1(X_1, X_2), Node2(X_1, X_2)) = AND(OR(X_1, X_2), NAND(X_1, X_2))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note that your weights will be different every time you fit the model. It's due to the fact that weighs are initialized randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
